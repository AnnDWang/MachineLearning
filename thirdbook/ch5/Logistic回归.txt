假设有一些数据点，我们用一条直线对这些点进行拟合，这个拟合过程称为回归。

Logistic回归的一般过程：
（1）收集数据：采用任意方法收集数据
（2）准备数据：由于需要进行距离计算，因此要求数据类型为数值型，另外，结构化数据格式则最佳
（3）分析数据：采用任意方法对数据进行分析
（4）训练算法：大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数
（5）测试算法：一旦训练步骤完成，分类将会很快
（6）使用算法：首先，我们需要输入一些数据，并将其转换成对应的结构化数值，接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定他们属于哪个类别，在这之后，我们就可以在输出的类别上做一些其它分析工作

Lofistic回归：

优点：计算代价不高，易于理解和实现
缺点：容易欠拟合，分类精度可能不高
适用数据类型：数值型和标称型数据

单位阶跃函数

梯度上升法：主要思想是要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。

随机梯度上升

weights.getA()解释：http://tieba.baidu.com/p/2905471495

matrix.getA()
Return self as an ndarray object.
Equivalent to np.asarray(self).
Parameters: None
Returns: ret : ndarrayself as an ndarray
也就是说矩阵通过这个getA()这个方法可以将自身返回成一个n维数组对象
为什么要这样做呢？
因为plotBestFit()函数中有计算散点x,y坐标的部分，其中计算y的时候用到了weights，如果weights是矩阵的话，weights[1]就是[[0.48007329]]（注意这里有中括号！），就不是一个数了，最终你会发现y的计算结果的len()只有1，而x的len()则是60，

处理数据中的缺失值：
使用可用特征的均值来填补缺失值
使用特殊值来填补缺失值，如-1
忽略有缺失值的样本
使用相似样本的均值填补缺失值
使用另外的机器学习算法预测缺失值


随机梯度上升与梯度上升算法的效果相当，但占用更少的计算资源。此外，随机梯度上升是一个在线算法，他可以在新数据到来时就完成参数更新，而不需要重新读取整个数据集来进行批处理运算